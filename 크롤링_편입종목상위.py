import requests
from bs4 import BeautifulSoup
import sys
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ random.pyì™€ì˜ ì¶©ëŒ ë°©ì§€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# URL ì„¤ì •
url = "https://finance.naver.com/sise/sise_index.naver?code=KPI200"

# í—¤ë” ì„¤ì • (User-Agent í•„ìˆ˜)
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

try:
    # ìš”ì²­ ì „ì†¡
    print("ğŸ“¡ í˜ì´ì§€ ìš”ì²­ ì¤‘...")
    response = requests.get(url, headers=headers, timeout=10)
    response.encoding = 'utf-8'
    
    if response.status_code == 200:
        print("âœ“ í˜ì´ì§€ ë¡œë“œ ì„±ê³µ\n")
        
        # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ëª¨ë“  í…Œì´ë¸” ì°¾ê¸°
        tables = soup.find_all('table')
        print(f"ë°œê²¬ëœ í…Œì´ë¸” ê°œìˆ˜: {len(tables)}\n")
        
        # ê° í…Œì´ë¸” ë¶„ì„
        for idx, table in enumerate(tables):
            rows = table.find_all('tr')
            if len(rows) > 0:
                # ì²« ë²ˆì§¸ í–‰ (í—¤ë”)
                first_row = rows[0]
                headers_list = [th.get_text(strip=True) for th in first_row.find_all(['th', 'td'])]
                
                if headers_list:
                    print(f"â”â”â” í…Œì´ë¸” {idx} â”â”â”")
                    print(f"í—¤ë”: {headers_list}")
                    
                    # ë°ì´í„° í–‰ í™•ì¸ (ì²˜ìŒ 3ê°œë§Œ)
                    for i, row in enumerate(rows[1:4]):
                        cols = row.find_all('td')
                        if cols:
                            row_data = [col.get_text(strip=True) for col in cols]
                            print(f"í–‰{i+1}: {row_data}")
                    print()
    
    else:
        print(f"âœ— ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")

except Exception as e:
    print(f"âœ— ì—ëŸ¬ ë°œìƒ: {e}")
    import traceback
    traceback.print_exc()
