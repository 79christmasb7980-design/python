"""
ë„¤ì´ë²„ ê¸ˆìœµ - ì½”ìŠ¤í”¼200 í¸ì…ì¢…ëª©ìƒìœ„ ë°ì´í„° í¬ë¡¤ë§
URL: https://finance.naver.com/sise/sise_index.naver?code=KPI200
"""

import requests
from bs4 import BeautifulSoup
import re

# URL ì„¤ì •
url = "https://finance.naver.com/sise/sise_index.naver?code=KPI200"

# í—¤ë” ì„¤ì • (User-Agent í•„ìˆ˜)
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def crawl_top_items():
    """
    í¸ì…ì¢…ëª©ìƒìœ„ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        print("ğŸ“¡ í˜ì´ì§€ ìš”ì²­ ì¤‘...\n")
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        if response.status_code != 200:
            print(f"âœ— ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            return None
        
        print("âœ“ í˜ì´ì§€ ë¡œë“œ ì„±ê³µ\n")
        
        # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # í¸ì…ì¢…ëª©ìƒìœ„ ì„¹ì…˜ ì°¾ê¸°
        # ë³´í†µ "í¸ì…ì¢…ëª©ìƒìœ„"ë¼ëŠ” í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í—¤ë”© ì°¾ê¸°
        target_section = None
        
        # ë°©ë²• 1: h2ë‚˜ h3 íƒœê·¸ì—ì„œ "í¸ì…" í…ìŠ¤íŠ¸ ì°¾ê¸°
        for heading in soup.find_all(['h2', 'h3', 'h4']):
            if 'í¸ì…' in heading.get_text():
                print(f"ì„¹ì…˜ ì œëª© ë°œê²¬: {heading.get_text()}")
                target_section = heading
                break
        
        # ë°©ë²• 2: divë‚˜ section íƒœê·¸ì˜ classë‚˜ idì—ì„œ ì°¾ê¸°
        if not target_section:
            for elem in soup.find_all('div', class_=True):
                if 'í¸ì…' in elem.get_text()[:200]:  # ì²˜ìŒ 200ìë§Œ í™•ì¸
                    text = elem.get_text(strip=True)
                    if 'í¸ì…ì¢…ëª©ìƒìœ„' in text:
                        target_section = elem
                        print(f"ì„¹ì…˜ div ë°œê²¬: {text[:100]}")
                        break
        
        # ë°©ë²• 3: ëª¨ë“  í…Œì´ë¸” í™•ì¸
        print("\nâ”â”â” ëª¨ë“  í…Œì´ë¸” ë¶„ì„ â”â”â”\n")
        tables = soup.find_all('table')
        
        for idx, table in enumerate(tables):
            rows = table.find_all('tr')
            
            if len(rows) == 0:
                continue
            
            # ì²« ë²ˆì§¸ í–‰ (í—¤ë”)
            first_row_cells = rows[0].find_all(['th', 'td'])
            headers_list = [cell.get_text(strip=True) for cell in first_row_cells]
            
            # í¸ì…ì¢…ëª©ì´ë‚˜ ìƒìœ„ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
            header_text = ' '.join(headers_list)
            
            print(f"í…Œì´ë¸” #{idx}")
            print(f"í—¤ë”: {headers_list}")
            
            # ë°ì´í„° í–‰ ì¶œë ¥
            print("ë°ì´í„° í–‰:")
            data_rows = []
            for i, row in enumerate(rows[1:11]):  # ì²˜ìŒ 10ê°œ í–‰
                cols = row.find_all('td')
                if cols:
                    row_data = [col.get_text(strip=True) for col in cols]
                    data_rows.append(row_data)
                    print(f"  {i+1}: {row_data}")
            
            print()
            
            # í¸ì…ì¢…ëª©ìƒìœ„ í…Œì´ë¸”ì¸ì§€ íŒë‹¨
            # ë³´í†µ ì¢…ëª©ëª…, í¸ì…ë¥ (%) ë“±ì˜ ì—´ì´ ìˆìŒ
            if any(keyword in header_text for keyword in ['ì¢…ëª©', 'í¸ì…', 'ë¹„ì¤‘', 'ê°€ê²©', 'ë³€ë™']):
                print(f"â†’ í…Œì´ë¸” #{idx}ê°€ í¸ì…ì¢…ëª©ìƒìœ„ ë°ì´í„°ë¡œ ë³´ì…ë‹ˆë‹¤!\n")
                return {
                    'headers': headers_list,
                    'data': data_rows,
                    'table_index': idx
                }
        
        return None
        
    except Exception as e:
        print(f"âœ— ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


def print_results(results):
    """
    í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì„œ ì¶œë ¥
    """
    if not results:
        print("í¸ì…ì¢…ëª©ìƒìœ„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("â”â”â” í¸ì…ì¢…ëª©ìƒìœ„ ë°ì´í„° â”â”â”\n")
    
    headers = results['headers']
    data = results['data']
    
    # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
    print(f"ì»¬ëŸ¼: {' | '.join(headers)}")
    print("-" * 100)
    
    for row in data:
        print(" | ".join(row))


if __name__ == "__main__":
    results = crawl_top_items()
    
    if results:
        print_results(results)
        print(f"\nâœ“ ìˆ˜ì§‘ëœ ì¢…ëª© ê°œìˆ˜: {len(results['data'])}")
    else:
        print("\nâŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
